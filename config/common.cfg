//
// Map parameters
//
Map.DataDir = /home/alex/Data/sequences
// Location of the original (color) images
Map.OrigFramesDir = /home/alex/Data
// Whether to load the original image files or the mono ones saved by PTAM
Map.LoadOriginalFrames = 1
// The default image size for cameras
Map.DefaultImageSize = [ 640 480 ];
// The default camera parameters
// Calibration for Lumix TZ3 video at 640x480, 30 fps, calibration residual error was 0.48 pixels
Map.DefaultCameraParameters = [ 0.838677 1.12028 0.511791 0.494215 0 ]
// Whether to approximate the camera by a first-order taylor expansion
Map.LinearizeCamera = 1

// temp, delete soon
Camera.Parameters = [ 0.838677 1.12028 0.511791 0.494215 0 ]

//
// Line detector parameters
//
// Minimum size for line segments is the maximum of these two parameters...
LineDetector.MinCompSize = .025  // as fraction of image size
//LineDetector.MinCompSize = .2  // temporarily use really large components
// Minimum size for line segments, as fraction of image size
LineDetector.MinCompSizePixels = 10  // as absolute number of pixels
// Number of orientation bins
LineDetector.NumOrientBins = 16
// Tolerance for tracing connected components, in terms of orient bins
LineDetector.OrientTol = 1

//
// Vanishing point detector parameters
//
// Default algorithm to use
VanPts.DefaultStrategy = EM  // Can be "EM" or "Ransac"
// Number of vanishing points
VanPts.NumVanishingPts = 3
// Number of k-means components for bootstrap
VanPts.NumBootstrapClusters = 3
// Minimum support for a kmeans cluster to be used in bootstrapping
VanPts.MinBootstrapSupport = 2;
// Bandwidth for the error model that relates vanishing points and
// line segments:
//    p(line_segment | vanishing_point) = Gauss( . ; sigma)
EMVanPts.ErrorModelSigma = 0.001
// Threshold for merging two vanishing points during EM
EMVanPts.MergeThreshold = 0.00001
// Threshold for exiting EM
EMVanPts.ExitThreshold = 0.00000001
// Log likelihood for spurious (not axis aligned) edges
EMVanPts.SpuriousLogLik = -5000.0
// Threshold below which an existing vanishing point adopts a new line
EMVanPts.AdoptThreshold = 0.01

// Number of ransac iterations
RansacVanPts.NumIterations = 10000
// Threshold below which a line "votes" for a propose vanpt
RansacVanPts.VoteThreshold = 0.05

// Extra image padding in vanishing point vizualization
VanPtsViz.ImagePadding = 100
// Alpha for drawing vanishing point extension lines
VanPtsViz.VanLineAlpha = 0.2

//
// K-means cluster parameters
//
KMeans.MaxIterations = 100
KMeans.ExitThreshold = 0.000001

//
// Segmenter params
//
// Determines segment size (larger K => larger segment)
FHSegmenter.K = 150
// Minimum segment size
FHSegmenter.MinSize = 50
// Threshold below which pixels will automatically be grouped
FHSegmenter.MinDiff = 1
// Smoothing bandwidth applied before segmentation
FHSegmenter.SmoothingSigma = 0.8


//
// Plane classifier params
//
// How far outside image regions to look for line segments
GeomLabeller.SearchRadiusMult = 0.3
// Minimum fraction of connected pixels for region/line adjacency
GeomLabeller.MinConnectedPixels = 0.4

//
// Consensus vanpts params
//
ConsVanPts.NumIterations = 200
ConsVanPts.VoteThreshold = 0.01

//
// Canny line detector parameters
//
// Bandwidth for smoothing before line detection
Gradients.SmoothingSigma = 0.0 // uh oh, changed from 1.0 on 7mar2011 due to removal of VW
Canny.ThreshLow = 20        // 10
Canny.ThreshHigh = 100       // 30
Canny.NumOrientBins = 16
Canny.NumThreads = 4
MultiScaleCanny.NumScales = 1

//
// Sobel convolution parameters
//
// Binary variable indicating whether or not to parallelize sobel
// convolutions. If true, number of threads will be determined
// automatically from hardware type.	
Sobel.Parallelize = 0  // turned this off for MEX

//
// Filter bank parameters
//
FilterBank.DefaultParallelism = "CPU-Sequential"  // CPU-Sequential, CPU-Parallel, or GPU


//
// Texton parameters
//
// Parameters for Gabor filters
Textons.Filters.NumScales = 3
Textons.Filters.NumOrients = 4

// What type of color information to include in the feature vector
Textons.Features.ColorInfo = 2  // = RGB colors
// Weighting for Gabor filter components of feature vector
Textons.Features.GaborWeight = 1.0
// Weightings for Mono component of feature vector
Textons.Features.MonoWeight = 1.0
// Weighting for RGB components of feature vector
Textons.Features.RWeight = 6.0
Textons.Features.GWeight = 6.0
Textons.Features.BWeight = 6.0
// Weighting for HSV components of feature vector.
Textons.Features.HWeight = 6.0
Textons.Features.SWeight = 2.0
Textons.Features.VWeight = 2.0

// Strategy for filtering
Textons.FilterStrategy = "CPUParallel"  // CPU, CPUParallel, or GPU

// File containing the texton vocabulary
Textons.VocabFile = "vocab.txt"
// Directory for caching texton maps. Cache keys are based on the MD5
// sum of the keyframe image provided in map.xml.
Textons.Mapper.CacheDir="texton-cache"

//
// Line sweeper parameters
//

// Extension to add to end of potentially-blocking line segments when
// sweeping
LineSweeper.BlockMarginSqr = 0

//
// Parameters for the rotation estimation gradient descent
//
RotationEstimator.AbsTol = 0.0001
RotationEstimator.RelTol = 0.000001
RotationEstimator.MaxSteps = 10;


//
// The map vizualizer settings
//
MapViz.RenderVpts=0
MapViz.RenderProjectedLines=0
MapViz.RenderPeakPlanes=1
// Factor to move retina plane by when pressing , or .
MapViz.RetinaPosDelta=1.3

//
// UI parameters
//
GlutWindow.DoubleClickTime = 0.2  // in seconds

//
// Parameters for the vpt-guided line detector
//

// Threshold on gradient magnitude for a pixel to become an edge
GuidedLineDetector.MagThresh = 7
// To decide if a pixel is assocated with a vanishing point we draw a
// line from the vanishing point to the pixel center and compute the
// distance from that line to the end of the one-pixel-long tangent
// vector at the pixel. If less than this threshold, it counts.
GuidedLineDetector.DistThresh = 0.1
// Minimum number of support pixels for a local maximum in the
// histogram to be counted as a line.
GuidedLineDetector.MinPeak = 2000



//
// ManhattanDP Parameters
//

// The default penalty per wall (for regularisation)
ManhattanDP.DefaultWallPenalty = 400
// The default penalty per occluding corner (in _addition_ to the per-wall penalty)
ManhattanDP.DefaultOcclusionPenalty = 300
// The size of the grid in which we perform the DP
// Make the height large so we can model scenes with walls extending outside the image bounds
ManhattanDP.GridSize = [ 320 480 ]
// If we arrive at a pixel such that the distance from the pixel
// centre to the line, divided by the distance from the pixel centre
// to the source, is less than this threshold, then delegate to that
// pixel and don't search any further.
ManhattanDP.LineJumpThreshold = 0.01  // measured in pixels

//
// Parameters for computing payoffs from 3D data
//
// Bandiwdth of gaussian describing agreement between wall hypotheses and 3D points, in grid pixels
LandmarkPayoffs.AgreeSigma = 1.5

//
// Parameters for finding sequences and their maps
//
Sequences.DataDir = /home/alex/Data/sequences
Sequences.MapPath = ground_truth/truthed_map.pro

//
// Photometric features for Manhattan reconstruction
//
BuildingFeatures.DefaultSet = "all"
BuildingFeatures.GaborScales = 3
BuildingFeatures.GaborOrientations = 6
BuildingFeatures.FirstWindowForSweeps = 5
BuildingFeatures.NumScalesForSweeps = 3

//
// Device and calibration parameters for the Kinect
//
Kinect.CalibrationDir = "/home/alex/Code/indoor_context/config/kinect_calibration"

//
// Interfacing with SVM-light
//
SVMLight.ScratchDir = "svm_scratch";
SVMLight.DefaultVerbosity = 0;
SVMLight.DefaultMarginPenalty = 0.1;
SVMLight.PrintCommands = 0;

SVMLight.BaseDir = "/home/alex/Install/libsvm";
SVMLight.TrainCmd = "svm_learn";
SVMLight.ClassifyCmd = "svm_classify";

SVMLight.MultiClass.BaseDir = "/home/alex/Install/svm_multiclass";
SVMLight.MultiClass.TrainCmd = "svm_multiclass_learn";
SVMLight.MultiClass.ClassifyCmd = "svm_multiclass_classify";


//
// Bootstrap training the DP
//
// Whether to weight errors in the SVM optimization according to the
// ratio of positive to negative examples.
Bootstrap.BalanceC = 1;
Bootstrap.FeatureStride = 3;
Bootstrap.NumIterations = 100;

// Total num samples in initial set - should be divisible by 3(=numclasses)
Bootstrap.InitSampleSize = 300;
// Whether to balance the initial training set
Bootstrap.BalanceInitSamples = 1;

// Number of samples to add each iteration
Bootstrap.IncSampleSize = 90;
// Whether to balance the incremental training samples
Bootstrap.BalanceIncSamples = 1;

// How often to perform each type of visualization (0 = never)							
Bootstrap.DrawSolutionsPeriod = 1;
Bootstrap.DrawActivePeriod = 1;
Bootstrap.DrawPayoffsPeriod = 10;
Bootstrap.DrawObjectivesPeriod = 10;


//
// One-shot training of manhattan reconstructions
//
Oneshot.TrainSequence = "lab_kitchen1";
Oneshot.TrainFrames = "10:10:90";
Oneshot.NumTrainPixels = 3000;

Oneshot.TestSequence = "lab_kitchen1";
Oneshot.TestFrames = "5:10:90";
Oneshot.FeatureSet = "rgb,hsv,sweeps,accum_sweeps";
Oneshot.VisualizeFeatures = 1;

//
// Parameters for the structure recovery algorithm of Lee et al
//

// Threshold at which a corner is considered to be an "occluding"
// corner. If two horizontal lines meet within this threhold at the
// corner then the corner is either concave or convex.
ManhattanRecovery.CnrOcclusionThresh = 5
// Never add two edges within this number of pixels from each other
ManhattanRecovery.MinCornerMargin = 10
// Maxmimum number of corners to add (not including the initial two)
ManhattanRecovery.MaxCorners = 2
// Resolution at which surface orientations are predicted and compared
ManhattanRecovery.OrientRes = 50




//
// Joint payoffs
//
// Weight for monocular features
JointPayoffs.Mono.Weight = 0.001;
// Weight for walls that contain 3D points
JointPayoffs.3D.AgreementWeight = 1000;  # 1200 for 3D-only
// Weight for walls that don't occlude 3D points
JointPayoffs.3D.OcclusionWeight = 40;  # 60 for 3D-only
// Weight for stereo photoconsistency
JointPayoffs.Stereo.Weight = 50;   # was 250 for stereo-only


//
// Joint Manhattan inference
//
// Visualization controls
JointDP.Output.DrawPayoffs = 0
// Which frames to use for stereo (relative to the base frame)
JointDP.Stereo.AuxOffsets = "-1,1"

// Base dir for results
//JointDP.ResultsDir = "/home/alex/Code/indoor_context/results"



//
// Semantic SfM segmentation of Brostow et al (ECCV, 2008)
//
// Window size for feature integration
Brostow.WindowSize = 72;  // based on their quoted size of 15% of image dimensions
Brostow.NumTrainingPixels = 50000
Brostow.TestPixelStride = 5;
Brostow.MarginPenalty = 100