/** 
 * Read bundle files as generated by Noah Snavley's Bundler
 */

#include <boost/filesystem.hpp>
#include <boost/foreach.hpp>

#include <TooN/SVD.h>

#include "entrypoint_types.h"
#include "viewer3d.h"
#include "widget3d.h"
#include "map_widgets.h"
#include "map_io.h"
#include "vanishing_points.h"
#include "guided_line_detector.h"

#include "format_utils.tpp"

/*Vec2 BundlerRetToIm(const Vec2& ret, double focal, const Vec2& distortion) {
	double nsq = norm_sq(ret);
	double r = 1. * distortion[0]*nsq + distortion[1]*nsq*nsq;
	return focal * r * ret;
}

Vec2 BundlerImToRet(const Vec2& ret, double focal, const Vec2& distortion) {
	double nsq = norm_sq(ret);
	double r = 1. + distortion[0]*nsq + distortion[1]*nsq*nsq;
	return focal * r * ret;
	}*/

SO3<> EstimateManhattanRotation(const Map& map, const SO3<>& init) {
	Mat3 cam = map.camera->Linearize();

	// Detect lines in each keyframe
	CannyLineDetector line_detector;
	vector<LineDetection> detections;
	vector<double> normalizations;
	BOOST_FOREACH(const Frame& frame, map.frames) {
		CHECK(frame.image.loaded());
		line_detector.Compute(frame.image);
		if (frame.id % 100 == 0) {
			line_detector.OutputLineViz(fmt("out/frame%03d_canny.png", frame.id));
		}

		// Here we ignore the translation component of the pose since this
		// is irrelevant for vanishing points.
		Mat3 H = cam * frame.image.pc().pose().get_rotation().get_matrix();
		BOOST_FOREACH(LineDetection& det, line_detector.detections) {
			LineDetection global_det = det;
			global_det.eqn = H.T() * global_det.eqn;
			detections.push_back(global_det);
			normalizations.push_back(norm(global_det.eqn.slice<0,2>()));
		}
	}

	// Estimate vanishing points
	DREPORT(detections.size());
	ManhattanFrameEstimator manhattan_est;
	manhattan_est.Compute(detections, init);
	return manhattan_est.R;
}

SO3<> EstimateRotationFromTrajectory(const Map& map) {
	// Get trajectory
	vector<Vec3> trajectory;
	Vec3 sum = Zeros;
	for (int i = 0; i < map.frames.size(); i++) {
		trajectory.push_back(map.frames[i].image.pc().world_centre());
		sum += trajectory[i];
	}
	Vec3 trajectory_centroid = sum / map.frames.size();

	// Form a matrix
	Matrix<> cmat(trajectory.size(), 3);
	for (int i = 0; i < map.frames.size(); i++) {
		cmat.slice(i,0,1,3) = (trajectory[i] - trajectory_centroid).as_row();
	}

	// Compute SVD
	SVD<> svd(cmat);

	// Get rotation
	Mat3 traj_R;
	traj_R[0] = unit(svd.get_VT()[0]);
	traj_R[1] = unit(svd.get_VT()[1]);
	traj_R[2] = unit(svd.get_VT()[2]);
	return SO3<>(traj_R).inverse();
}

int main(int argc, char **argv) {
	InitVars(argc, argv);

	if (argc != 2 && argc != 3) {
		DLOG << "Usage: "<<argv[0]<<" bundle/bundle.out list.txt";
		DLOG << "       "<<argv[0]<<" DIR";
		return -1;
	}

	Map map;
	if (argc == 2) {
		LoadBundlerMap(argv[1], map);
	} else {
		LoadBundlerMap(argv[1], argv[2], map);
	}
	map.LoadAllImages();

	SO3<> traj_R = EstimateRotationFromTrajectory(map);
	SO3<> R = EstimateManhattanRotation(map, traj_R);

	DREPORT(R, traj_R);

	map.Transform(R.inverse());

	map.Normalize(5.);

	GuidedLineDetector g;
	for (int i = 0; i < map.frames.size(); i += 10) {
		g.Compute(map.frames[i].image);
		g.OutputSegmentsViz(fmt("out/frame%03d_segs.png", i));
		g.OutputSceneAxesViz(fmt("out/frame%03d_axes.png", i));
	}

	Viewer3D v;
	v.AddOwned(new GroundPlaneWidget);
	v.AddOwned(new PointCloudWidget(map.points));
	for (int i = 0; i < map.frames.size(); i++) {
		v.AddOwned(new FrameWidget(map.frames[i], .2));
	}
	v.Run();

	return 0;
}
